{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Deeplake Vector Store\n",
    "Here, we will explore how to work with Deeplake. We are using OpenAI from Indox Api, we should set our INDOX_OPENAI_API_KEY as an environment variable.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/Demo/Deeplake_VectorStore.ipynb)"
   ],
   "id": "96fd36cb644c686c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:22.422539Z",
     "start_time": "2024-09-02T03:03:22.368541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install indox\n",
    "!pip install openai\n",
    "!pip install deeplake"
   ],
   "id": "b052f757a9627eec",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indox`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indox\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indox_judge\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indox\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indox/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ],
   "id": "2d1919b4993c54b2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:22.506606Z",
     "start_time": "2024-09-02T03:03:22.439003Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "INDOX_API_KEY= os.getenv(\"INDOX_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating an instance of IndoxTetrivalAugmentation\n",
    "\n",
    "To effectively utilize the Indox Retrieval Augmentation capabilities, you must first create an instance of the IndoxRetrievalAugmentation class. This instance will allow you to access the methods and properties defined within the class, enabling the augmentation and retrieval functionalities."
   ],
   "id": "215511a752e8ed9b"
  },
  {
   "metadata": {
    "id": "482156866f7df32c",
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:23.472072Z",
     "start_time": "2024-09-02T03:03:22.512312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "indox = IndoxRetrievalAugmentation()"
   ],
   "id": "482156866f7df32c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mIndoxRetrievalAugmentation initialized\u001B[0m\n",
      "\n",
      "            ██  ███    ██  ██████   ██████  ██       ██\n",
      "            ██  ████   ██  ██   ██ ██    ██   ██  ██\n",
      "            ██  ██ ██  ██  ██   ██ ██    ██     ██\n",
      "            ██  ██  ██ ██  ██   ██ ██    ██   ██   ██\n",
      "            ██  ██  █████  ██████   ██████  ██       ██\n",
      "            \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generating response using Indox\n",
    "IndoxApi class is used to handle question-answering task using Indox model. This instance creates IndoxOpenAIEmbedding class to specifying embedding model.By using ClusteredSplit function we can import pdf and text file and split them into chunks."
   ],
   "id": "925448e261063192"
  },
  {
   "metadata": {
    "id": "5840d601bf111608",
    "outputId": "34a39efd-1e37-478a-83c7-a7c1b255805b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:48.306156Z",
     "start_time": "2024-09-02T03:03:23.475621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary classes from Indox library\n",
    "from indox.llms import IndoxApi\n",
    "from indox.embeddings import IndoxApiEmbedding\n",
    "from indox.data_loader_splitter import ClusteredSplit\n",
    "\n",
    "# Create instances for API access and text embedding\n",
    "openai_qa_indox = IndoxApi(api_key=INDOX_API_KEY)\n",
    "embed_openai_indox = IndoxApiEmbedding(api_key=INDOX_API_KEY, model=\"text-embedding-3-small\")\n",
    "\n",
    "# Specify the path to your text file\n",
    "file_path = \"sample.txt\"\n",
    "\n",
    "# Create a ClusteredSplit instance for handling file loading and chunking\n",
    "loader_splitter = ClusteredSplit(file_path=file_path, embeddings=embed_openai_indox, summary_model=openai_qa_indox)\n",
    "\n",
    "# Load and split the document into chunks using ClusteredSplit\n",
    "docs = loader_splitter.load_and_chunk()"
   ],
   "id": "5840d601bf111608",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitialized IndoxOpenAIEmbedding with model: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mClusteredSplit initialized successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting processing for documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1m--Generated 1 clusters--\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted chunking & clustering process\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mSuccessfully obtained all documents\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Here Deeplake VectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried.",
   "id": "5ea4f79c9ab9f622"
  },
  {
   "metadata": {
    "id": "72d8e01f62f1f4d",
    "outputId": "422e7f26-4a2f-40dd-9d88-cb1e356b3477",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:53.908685Z",
     "start_time": "2024-09-02T03:03:48.306156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.vector_stores import Deeplake\n",
    "collection_name = \"sample\"\n",
    "\n",
    "db = Deeplake(collection_name=collection_name, embedding_function=embed_openai_indox)\n"
   ],
   "id": "72d8e01f62f1f4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in /content/vector_store/sample already exists, loading from the storage\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### load and preprocess data\n",
    "This part of code demonstrates how to load and preprocess text data from a file, split it into chunks, and store these chunks in the vector store that was set up previously."
   ],
   "id": "9558c3c6c9708704"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:56.554907Z",
     "start_time": "2024-09-02T03:03:53.908685Z"
    }
   },
   "cell_type": "code",
   "source": "db.add(docs=docs)",
   "id": "f6706e55517d7ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2::   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='/content/vector_store/sample', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (48, 1536)  float32   None   \n",
      "    id        text      (48, 1)      str     None   \n",
      " metadata     json      (48, 1)      str     None   \n",
      "   text       text      (48, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:56.581676Z",
     "start_time": "2024-09-02T03:03:56.554907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"How cinderella reach her happy ending?\"\n",
    "retriever = indox.QuestionAnswer(vector_database=db, llm=openai_qa_indox, top_k=5)"
   ],
   "id": "25eee706fb500090",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "invoke(query) method sends the query to the retriever, which searches the vector store for relevant text chunks and uses the language model to generate a response based on the retrieved information.\n",
    "Context property retrieves the context or the detailed information that the retriever used to generate the answer to the query. It provides insight into how the query was answered by showing the relevant text chunks and any additional information used."
   ],
   "id": "3fe6dd7ef78f5665"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:59.848514Z",
     "start_time": "2024-09-02T03:03:56.581676Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.invoke(query)",
   "id": "48544e1ff1cf2e07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mRetrieving context and scores from the vector database\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating answer without document relevancy filter\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mQuery answered successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cinderella reaches her happy ending through a series of transformative events that lead to her escape from a life of hardship and her eventual union with the prince. Here’s a summary of the key steps in her journey:\\n\\n1. **Kindness and Resilience**: Despite being mistreated by her stepmother and stepsisters, Cinderella remains kind and hopeful. Her resilience in the face of adversity sets the foundation for her eventual happiness.\\n\\n2. **The Invitation to the Ball**: When the royal family announces a ball to which all young women are invited, Cinderella dreams of attending. Although her stepfamily forbids her from going, her desire to participate in the event highlights her longing for a better life.\\n\\n3. **The Fairy Godmother**: In'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "a2d500d6244768cb",
    "outputId": "2de11787-ee0b-4be5-caeb-556edab1bcbb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-09-02T03:03:59.864134Z",
     "start_time": "2024-09-02T03:03:59.848514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever.context"
   ],
   "id": "a2d500d6244768cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The documentation provided appears to be the beginning of a narrative or story. It introduces a situation where the wife of a wealthy man is gravely ill and senses that her life is coming to an end. In her final moments, she calls for her only daughter to come to her bedside. This sets the stage for an emotional and significant conversation between the mother and daughter, likely involving important life lessons, family values, or the transfer of wisdom and responsibilities.\\n\\nThe context suggests themes of love, family bonds, and the inevitability of death, as well as the emotional weight of a parent imparting final thoughts or wishes to their child. The narrative likely explores the relationship dynamics between the mother and daughter, and may also touch upon the implications of wealth and the',\n",
       " 'The provided documentation appears to be the beginning of a narrative or story. It introduces a scenario where the wife of a wealthy man is gravely ill and senses that her life is nearing its end. In this moment of vulnerability, she calls for her only daughter to come to her bedside. The use of the term \"dear child\" indicates a deep emotional connection between the mother and daughter, suggesting that the mother wishes to impart something important or meaningful to her daughter before she passes away.\\n\\nWhile the excerpt does not provide further details about the conversation or the themes that may be explored in the story, it sets the stage for a potentially poignant moment that could involve themes of love, legacy, family, and the transmission of wisdom or values from one generation to',\n",
       " 'The provided documentation appears to be the beginning of a narrative or story. It introduces a scenario where the wife of a wealthy man is gravely ill and senses that her life is coming to an end. In this moment of impending death, she calls for her only daughter to come to her bedside. The phrase \"dear child\" suggests a tone of affection and concern, indicating the mother\\'s deep emotional connection to her daughter as she prepares to impart important thoughts or wishes.\\n\\nThe context implies themes of family, love, and perhaps the passing of wisdom or legacy from mother to daughter. The situation sets the stage for a pivotal moment in the story, likely involving the mother\\'s final words, advice, or a request that could have significant implications for the daughter and possibly',\n",
       " 'The documentation appears to be the beginning of a narrative or story. It introduces a scenario where the wife of a wealthy man is gravely ill and senses that her life is coming to an end. In her final moments, she calls for her only daughter to come to her bedside. This setup suggests themes of family, wealth, mortality, and possibly the passing of wisdom or legacy from mother to daughter.\\n\\nThe mention of the mother\\'s illness and her awareness of her impending death indicates a poignant emotional context, likely leading to a significant conversation or imparting of important messages or values to her daughter. The use of the term \"dear child\" implies a close and affectionate relationship between the mother and daughter, which may play a crucial role in the unfolding of the']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
