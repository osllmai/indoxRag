{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LanternDB\n",
    "In this notebook, we will demonstrate how to use LanternDB, for accessing and querying data efficiently. LanternDB is designed to work seamlessly with modern analytical workloads, making it a powerful tool for data analysis, research, and question-answering systems.\n",
    "\n",
    "To begin, ensure you have LanternDB installed in your Python environment. You can easily install it using `pip install pgcopg2`. so you can start querying data directly in your local environment without any additional setup.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/Demo/lanterndb.ipynb)"
   ],
   "id": "6c416e33efe74032"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install indox\n",
    "!pip install psycopg2\n",
    "!pip install semantic_text_splitter\n",
    "!pip install sentence-transformers"
   ],
   "id": "6ff860b3e1246531"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indox`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indox\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indox_judge\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indox\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indox/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ],
   "id": "68ddd9e06704e8c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Hugging face API key \n",
   "id": "246f20d8186160f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "79b0ba9fc233722f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:19:56.966480Z",
     "start_time": "2024-09-08T14:19:56.956886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('api.env')\n",
    "HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')"
   ],
   "id": "4ceeb43c88eb0f92",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:19:58.402883Z",
     "start_time": "2024-09-08T14:19:58.380045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "indox = IndoxRetrievalAugmentation()"
   ],
   "id": "3e0cb75b39306d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mIndoxRetrievalAugmentation initialized\u001B[0m\n",
      "\n",
      "            ██  ███    ██  ██████   ██████  ██       ██\n",
      "            ██  ████   ██  ██   ██ ██    ██   ██  ██\n",
      "            ██  ██ ██  ██  ██   ██ ██    ██     ██\n",
      "            ██  ██  ██ ██  ██   ██ ██    ██   ██   ██\n",
      "            ██  ██  █████  ██████   ██████  ██       ██\n",
      "            \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialize a language model and an embedding model using the indox library with Hugging Face . The HuggingFaceModel class is used to create an instance of the Mistral-7B-Instruct model for tasks like question answering",
   "id": "fa5b6054d57943f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:06.428643Z",
     "start_time": "2024-09-08T14:20:00.047537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.llms import HuggingFaceModel\n",
    "from indox.embeddings import HuggingFaceEmbedding\n",
    "mistral_qa = HuggingFaceModel(api_key=HUGGINGFACE_API_KEY,model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "embed = HuggingFaceEmbedding(api_key=HUGGINGFACE_API_KEY,model=\"multi-qa-mpnet-base-cos-v1\")"
   ],
   "id": "d4b122b67b62a902",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitializing HuggingFaceModel with model: mistralai/Mistral-7B-Instruct-v0.2\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mHuggingFaceModel initialized successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitialized HuggingFaceEmbedding with model: multi-qa-mpnet-base-cos-v1\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load sample text",
   "id": "79d2146b8c745697"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt\n",
   "id": "1ae66a77bd283acd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:06.436738Z",
     "start_time": "2024-09-08T14:20:06.434307Z"
    }
   },
   "cell_type": "code",
   "source": "file_path = 'sample.txt'",
   "id": "772e5448163c94bc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:06.491601Z",
     "start_time": "2024-09-08T14:20:06.485675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    text = file.read()"
   ],
   "id": "d4f59422f7e45412",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "use the `SemanticTextSplitter` class from the indox library to divide a large text into smaller, manageable chunks",
   "id": "4ddc61c8d226e886"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:08.447082Z",
     "start_time": "2024-09-08T14:20:07.980599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.splitter import SemanticTextSplitter\n",
    "splitter = SemanticTextSplitter(400)\n",
    "content_chunks = splitter.split_text(text)"
   ],
   "id": "abaa6973fcdc5ee3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Set up vector store\n",
    "Set up a vector store using the `LanternDB` class from the indox library."
   ],
   "id": "11514c4c72eae13c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:14.647411Z",
     "start_time": "2024-09-08T14:20:10.575590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.vector_stores import LanternDB\n",
    "connection_params = {\n",
    "    \"dbname\": \"DatabaseName\",\n",
    "    \"user\": \"User\",\n",
    "    \"password\": \"password\",\n",
    "    \"host\": \"host\",\n",
    "    \"port\": \"port\"\n",
    "}\n",
    "lantern_db = LanternDB(\n",
    "    collection_name=\"Vector_collection\",\n",
    "    embedding_function=embed,\n",
    "    connection_params=connection_params,\n",
    "    dimension=768,\n",
    ")"
   ],
   "id": "5a94486559ba9879",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LanternDB collection 'Vector_collection'\n",
      "Collection 'Vector_collection' created successfully.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Storing Data in the Vector Store\n",
   "id": "4404beeb91b8186"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:22.537287Z",
     "start_time": "2024-09-08T14:20:17.056571Z"
    }
   },
   "cell_type": "code",
   "source": "lantern_db.add_texts(content_chunks)",
   "id": "abf7bdbe94e4580c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 9 documents into collection 'Vector_collection'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['852d6289-a105-48f3-94e8-4169f109abb7',\n",
       " '9de00e1c-736f-41f7-a4cf-2337bb62d5d7',\n",
       " 'f00c66ba-ba5e-4928-b7bc-980688a7efd2',\n",
       " '21c94f7b-ee16-4c49-b914-da0c2e5247c4',\n",
       " '09323629-9f81-4236-9619-c84e025f3b8f',\n",
       " 'b88cdb3a-79dd-48bf-b3d3-f44d7ee258be',\n",
       " '126dd7fb-4dba-4189-bfaa-c220fd69570e',\n",
       " 'c223a9a1-232e-493b-aa90-129a21d05d19',\n",
       " 'ebbcb9cc-c00e-4036-a942-28fb1f079d6e']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:22.692858Z",
     "start_time": "2024-09-08T14:20:22.689696Z"
    }
   },
   "cell_type": "code",
   "source": "query = \"How cinderella reach her happy ending?\"\n",
   "id": "da94506679714392",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:27.145267Z",
     "start_time": "2024-09-08T14:20:23.356157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = indox.QuestionAnswer(vector_database=lantern_db,llm=mistral_qa,top_k=5)\n",
    "answer = retriever.invoke(query)\n"
   ],
   "id": "e1507c295310beb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mRetrieving context and scores from the vector database\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating answer without document relevancy filter\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mAnswering question\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mSending request to Hugging Face API\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mReceived successful response from Hugging Face API\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mQuery answered successfully\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:20:27.562959Z",
     "start_time": "2024-09-08T14:20:27.557418Z"
    }
   },
   "cell_type": "code",
   "source": "answer",
   "id": "19abf4792769c9fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cinderella reached her happy ending by attending the royal ball in a beautiful dress and golden slippers that were magically provided to her by a little white bird that lived on a tree she had once wept and prayed under. The king's son fell in love with her and was determined to marry her, so he searched for the woman whose foot the golden slipper fit. When the two stepsisters attempted to wear the slipper, it didn't fit because Cinders\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
