{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/Demo/openai_agenticrag.ipynb)",
   "id": "cd1e2aa3a497e7b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install indox\n",
    "!pip install openai\n",
    "!pip install chromadb\n",
    "!pip install duckduckgo-search"
   ],
   "id": "c2ab8144e1eb7773"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indox`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indox\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indox\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indox\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indox/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ],
   "id": "594179f9be309e1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Agentic RAG\n",
    "Here, we will explore how to work with Agentic RAG. We are using OpenAI and we should set our OPENAI_API_KEY as an environment variable."
   ],
   "id": "e17682c35969a25"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-12T12:51:23.884950Z",
     "start_time": "2024-07-12T12:51:23.873448Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating an instance of IndoxRetrievalAugmentation\n",
    "You must first create an instance of IndoxRetrievalAugmentation class. This instance will allow you to access the methods and properties defined within the class, enabling the augmentation and retrieval functionalities."
   ],
   "id": "cc1864f1b50f95c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:51:33.474799Z",
     "start_time": "2024-07-12T12:51:23.886053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "from indox.llms import OpenAi\n",
    "from indox.embeddings import OpenAiEmbedding\n",
    "from indox.data_loader_splitter import SimpleLoadAndSplit"
   ],
   "id": "f86ed3314b0d078",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create OpenAi model as LLM_model and OpenAiEmbedding as Embedding model and using them to generate response.",
   "id": "a81302a67ec0d5a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:51:35.534540Z",
     "start_time": "2024-07-12T12:51:33.475809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indox = IndoxRetrievalAugmentation()\n",
    "llm_model = OpenAi(api_key=OPENAI_API_KEY,model=\"gpt-3.5-turbo-0125\")\n",
    "embed = OpenAiEmbedding(api_key=OPENAI_API_KEY,model=\"text-embedding-3-small\")"
   ],
   "id": "7b93033e005b8049",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mIndoxRetrievalAugmentation initialized\u001B[0m\n",
      "\n",
      "            ██  ███    ██  ██████   ██████  ██       ██\n",
      "            ██  ████   ██  ██   ██ ██    ██   ██  ██\n",
      "            ██  ██ ██  ██  ██   ██ ██    ██     ██\n",
      "            ██  ██  ██ ██  ██   ██ ██    ██   ██   ██\n",
      "            ██  ██  █████  ██████   ██████  ██       ██\n",
      "            \n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitializing OpenAi with model: gpt-3.5-turbo-0125\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mOpenAi initialized successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitialized OpenAI embeddings with model: text-embedding-3-small\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:51:35.541025Z",
     "start_time": "2024-07-12T12:51:35.535545Z"
    }
   },
   "cell_type": "code",
   "source": "indox.__version__",
   "id": "62398709ecd1bae2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.13'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### You can download the file from the below address ",
   "id": "2a0fb03eccb8cf95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt",
   "id": "7174373485eda383",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocess Data\n",
    "using SimpleLoadAndSplit class to preprocess text data from a file, split text into chunks"
   ],
   "id": "f9e40fa02a3110d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:51:55.977807Z",
     "start_time": "2024-07-12T12:51:55.973149Z"
    }
   },
   "cell_type": "code",
   "source": "loader_splitter = SimpleLoadAndSplit(file_path=\"sample.txt\",remove_sword=False)",
   "id": "3aaeda535bc2c497",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mUnstructuredLoadAndSplit initialized successfully\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:51:58.783182Z",
     "start_time": "2024-07-12T12:51:56.310684Z"
    }
   },
   "cell_type": "code",
   "source": "docs = loader_splitter.load_and_chunk()",
   "id": "e173124b75795645",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting processing\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCreated initial document elements\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted chunking process\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mSuccessfully obtained all documents\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create ChromaVectoreStore instance\n",
    "Here ChromaVectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
   ],
   "id": "8f82e6f2cb8dc57f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:51:59.444759Z",
     "start_time": "2024-07-12T12:51:58.784193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.vector_stores import Chroma\n",
    "\n",
    "# Define the collection name within the vector store\n",
    "collection_name = \"sample\"\n",
    "\n",
    "# Create a ChromaVectorStore instance\n",
    "db = Chroma(collection_name=collection_name, embedding_function=embed)\n"
   ],
   "id": "f8a8b4ca4328777e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mConnection to the vector store database established successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.Chroma.ChromaVectorStore at 0x208f44d0560>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "store the chunks in the vector store that was set up previously.",
   "id": "9535306c09023386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:52:10.498123Z",
     "start_time": "2024-07-12T12:52:03.238982Z"
    }
   },
   "cell_type": "code",
   "source": "db.add(docs=docs)",
   "id": "20b205c7b5cb3521",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mStoring documents in the vector store\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocument added successfully to the vector store.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocuments stored successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.Chroma.ChromaVectorStore at 0x208f44d0560>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Retrieve relevant information by question-answering model\n",
    "At this step we are using QuestionAnswer model and try to retrieve the answer just by our file and without any agent"
   ],
   "id": "f18cb82b795d12eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:52:10.501997Z",
     "start_time": "2024-07-12T12:52:10.499133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Where does messi plays right now?\"\n",
    "retriever = indox.QuestionAnswer(vector_database=db,llm=llm_model,top_k=3)"
   ],
   "id": "71e64d760fa319f0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:52:16.305913Z",
     "start_time": "2024-07-12T12:52:10.503005Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.invoke(query)",
   "id": "2d3ed87a223398fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mRetrieving context and scores from the vector database\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating answer without document relevancy filter\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mAnswering question\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mResponse generated successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mQuery answered successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the given context does not contain any information about Lionel Messi's current football club.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Retrieve information by using Agnet\n",
    "Here we are using Agent to retrieve answer. As you can see, our last try was unsuccessful but now after the agent couldn't find the answer it started to search on the internet.\n",
    "Note: to be more familiar with AgenticRAG pleas read [this page](\"https://docs.osllm.ai/agenticRag.html\")"
   ],
   "id": "b3846ee63c84dd1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T12:53:38.269935Z",
     "start_time": "2024-07-12T12:52:16.306919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = indox.AgenticRag(llm=llm_model,vector_database=db,top_k=3)\n",
    "agent.run(query)"
   ],
   "id": "5a145c1a46ced87d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mERROR\u001B[0m: \u001B[31m\u001B[1mError generating response: Request timed out.\u001B[0m\n",
      "\u001B[31mERROR\u001B[0m: \u001B[31m\u001B[1mError generating response: Request timed out.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mResponse generated successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mNot relevant doc\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mResponse generated successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mNot relevant doc\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mResponse generated successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mNot relevant doc\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mNo Relevant document found, Start web search\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mNo Relevant Context Found, Start Searching On Web...\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mAnswer Base On Web Search\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mAnswering question\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mResponse generated successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCheck For Hallucination In Generated Answer Base On Web Search\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mChecking hallucination for answer\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mResponse generated successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mHallucination detected, Regenerate the answer...\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mAnswering question\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mResponse generated successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Lionel Messi currently plays for Major League Soccer's Inter Miami CF.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "751c15421f42ebfa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
